# -*- coding: utf-8 -*-
"""singleton classifier analysis.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/10uBgw_cYJ1vWhSnOE8ckLvoK-AmGCuIz
"""

import json
import pandas as pd
import numpy as np
# from utils.data_helper import get_markable_dataframe, get_embedding_variables
from get_markabledataframe import get_markable_dataframe, get_embedding_variables
from functools import reduce
from IPython.display import HTML, display
from tabulate import tabulate
from html import escape

embedding_indexes_file_path = 'helper_files/embedding/embedding_indexes.txt'
indexed_embedding_file_path = 'helper_files/embedding/indexed_embedding.txt'

word_vector, embedding_matrix, idx_by_word, word_by_idx = get_embedding_variables(embedding_indexes_file_path, indexed_embedding_file_path)

markables_original_singletons = get_markable_dataframe("data/testing/markables_22_all.csv", word_vector, idx_by_word)
markables_predicted_singletons = get_markable_dataframe("data/testing/markables_with_predicted_singleton.csv", word_vector, idx_by_word)

# markables_original_singletons.head()

markables_predicted_singletons[markables_predicted_singletons['mention_id'].map(lambda x: x in [2655, 2677, 2692, 2693, 2697])]

def get_markable_text(idx):
    return ' '.join([word_by_idx[x] for x in markables_original_singletons[markables_original_singletons['mention_id'] == idx].mention.values[0]])

def get_markable_previous_words(idx):
    return ' '.join([word_by_idx[x] for x in markables_original_singletons[markables_original_singletons['mention_id'] == idx].previous_words.values[0]])

def get_markable_next_words(idx):
    return ' '.join([word_by_idx[x] for x in markables_original_singletons[markables_original_singletons['mention_id'] == idx].next_words.values[0]])

def get_markable(idx):
    return f'{get_markable_previous_words(idx)} [{get_markable_text(idx).upper()}] {get_markable_next_words(idx)}'.strip()

right_predicted_markables = markables_predicted_singletons[markables_predicted_singletons['is_singleton'].map(lambda x: x[0]) == markables_original_singletons['is_singleton'].map(lambda x: x[0])]
wrong_predicted_markables = markables_predicted_singletons[markables_predicted_singletons['is_singleton'].map(lambda x: x[0]) != markables_original_singletons['is_singleton'].map(lambda x: x[0])]

"""# Analysis of Wrongly Predicted Markables

## Label: singleton, predicted: non-singleton
"""
print("analysis of wrogly predicted markable")

false_negatives = wrong_predicted_markables[wrong_predicted_markables['is_singleton'].map(lambda x: x[0]) == 1]
false_negative_texts = [get_markable(idx) for idx in false_negatives['mention_id']]

data_to_analyze =  false_negatives

# print(f'"उनके": {len(list(filter(lambda x: get_markable_text(x) == "उनके", data_to_analyze["mention_id"])))}')
print(f'proper name: {len(data_to_analyze[data_to_analyze["is_proper_name"] == 1])}')
print(f'pronoun: {len(data_to_analyze[data_to_analyze["is_pronoun"] == 1])}')   
# print(f'pronoun without "उनके": {len(data_to_analyze[data_to_analyze["is_pronoun"] == 1]) - len(list(filter(lambda x: get_markable_text(x) == "उनके", data_to_analyze["mention_id"])))}')
print(f'first person: {len(data_to_analyze[data_to_analyze["is_first_person"] == 1])}')

data_to_analyze, text_data_to_analyze = false_negatives, false_negative_texts
print ("{:<8} {:<15} {:<10}".format('i','idx','text'))
for i, idx, text in zip(range(1, len(data_to_analyze) + 1), data_to_analyze['mention_id'], text_data_to_analyze):
   print ("{:<8} {:<15} {:<10}".format(i,idx,text))
# display(HTML(tabulate([
#     [i, idx, escape(text)]
#     for i, idx, text
#     in zip(range(1, len(data_to_analyze) + 1), data_to_analyze['mention_id'], text_data_to_analyze)
# ], tablefmt='html')))

"""## Label: non-singleton, predicted: singleton"""
print()

false_positives = wrong_predicted_markables[wrong_predicted_markables['is_singleton'].map(lambda x: x[0]) == 0]
false_positive_texts = [get_markable(idx) for idx in false_positives['mention_id']]

data_to_analyze =  false_positives

# print(f'"उनके": {len(list(filter(lambda x: get_markable_text(x) == "उनके", data_to_analyze["mention_id"])))}')
print(f'proper name: {len(data_to_analyze[data_to_analyze["is_proper_name"] == 1])}')
print(f'pronoun: {len(data_to_analyze[data_to_analyze["is_pronoun"] == 1])}')   
# print(f'pronoun without "nya": {len(data_to_analyze[data_to_analyze["is_pronoun"] == 1]) - len(list(filter(lambda x: get_markable_text(x) == "उनके", data_to_analyze["mention_id"])))}')
print(f'first person: {len(data_to_analyze[data_to_analyze["is_first_person"] == 1])}')

# data_to_analyze, text_data_to_analyze = false_positives, false_positive_texts
# for i, idx, text in zip(range(1, len(data_to_analyze) + 1), data_to_analyze['mention_id'], text_data_to_analyze):
#    print ("{:<8} {:<15} {:<10}".format(i,idx,text))

# display(HTML(tabulate([
#     [i, idx, escape(text)]
#     for i, idx, text
#     in zip(range(1, len(data_to_analyze) + 1), data_to_analyze['mention_id'], text_data_to_analyze)
# ], tablefmt='html')))

"""# Analysis of Rightly Predicted Markables

## Non-Singletons
"""
print("analysis of rightly predicted markable")

true_negatives = right_predicted_markables[right_predicted_markables['is_singleton'].map(lambda x: x[0]) == 1]
true_negative_texts = [get_markable(idx) for idx in true_negatives['mention_id']]

data_to_analyze =  true_negatives

# print(f'"उनके": {len(list(filter(lambda x: get_markable_text(x) == "उनके", data_to_analyze["mention_id"])))}')
print(f'proper name: {len(data_to_analyze[data_to_analyze["is_proper_name"] == 1])}')
print(f'pronoun: {len(data_to_analyze[data_to_analyze["is_pronoun"] == 1])}')   
# print(f'pronoun without "उनके": {len(data_to_analyze[data_to_analyze["is_pronoun"] == 1]) - len(list(filter(lambda x: get_markable_text(x) == "उनके", data_to_analyze["mention_id"])))}')
print(f'first person: {len(data_to_analyze[data_to_analyze["is_first_person"] == 1])}')

data_to_analyze, text_data_to_analyze = true_negatives, true_negative_texts
for i, idx, text in zip(range(1, len(data_to_analyze) + 1), data_to_analyze['mention_id'], text_data_to_analyze):
   print ("{:<8} {:<15} {:<10}".format(i,idx,text))
# # display(HTML(tabulate([
#     [i, idx, escape(text)]
#     for i, idx, text
#     in zip(range(1, len(data_to_analyze) + 1), data_to_analyze['mention_id'], text_data_to_analyze)
# ], tablefmt='html')))

"""## Singletons"""
print("analysis of singletons markable")

true_positives = right_predicted_markables[right_predicted_markables['is_singleton'].map(lambda x: x[0]) == 0]
true_positive_texts = [get_markable(idx) for idx in true_positives['mention_id']]

data_to_analyze =  true_positives

# print(f'"उनके": {len(list(filter(lambda x: get_markable_text(x) == "उनके", data_to_analyze["mention_id"])))}')
print(f'proper name: {len(data_to_analyze[data_to_analyze["is_proper_name"] == 1])}')
print(f'pronoun: {len(data_to_analyze[data_to_analyze["is_pronoun"] == 1])}')   
# print(f'pronoun without "उनके": {len(data_to_analyze[data_to_analyze["is_pronoun"] == 1]) - len(list(filter(lambda x: get_markable_text(x) == "उनके", data_to_analyze["mention_id"])))}')
print(f'first person: {len(data_to_analyze[data_to_analyze["is_first_person"] == 1])}')

data_to_analyze, text_data_to_analyze = true_positives, true_positive_texts
for i, idx, text in zip(range(1, len(data_to_analyze) + 1), data_to_analyze['mention_id'], text_data_to_analyze):
   print ("{:<8} {:<15} {:<10}".format(i,idx,text))

# display(HTML(tabulate([
#     [i, idx, escape(text)]
#     for i, idx, text
#     in zip(range(1, len(data_to_analyze) + 1), data_to_analyze['mention_id'], text_data_to_analyze)
# ], tablefmt='html')))