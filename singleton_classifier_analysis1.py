# -*- coding: utf-8 -*-
"""singleton classifier analysis.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/10uBgw_cYJ1vWhSnOE8ckLvoK-AmGCuIz
"""

import json
import pandas as pd
import numpy as np
from utils.data_helper import get_markable_dataframe, get_embedding_variables
from functools import reduce
from IPython.display import HTML, display
from tabulate import tabulate
from html import escape

embedding_indexes_file_path = 'helper_files/embedding/embedding_indexes.txt'
indexed_embedding_file_path = 'helper_files/embedding/indexed_embedding.txt'

word_vector, embedding_matrix, idx_by_word, word_by_idx = get_embedding_variables(embedding_indexes_file_path, indexed_embedding_file_path)

markables_original_singletons = get_markable_dataframe("data/testing/markables_22.csv", word_vector, idx_by_word)
markables_predicted_singletons = get_markable_dataframe("data/testing/markables_with_predicted_singleton.csv", word_vector, idx_by_word)

markables_original_singletons.head()

markables_predicted_singletons[markables_predicted_singletons['id'].map(lambda x: x in [2655, 2677, 2692, 2693, 2697])]

def get_markable_text(idx):
    return ' '.join([word_by_idx[x] for x in markables_original_singletons[markables_original_singletons['id'] == idx].text.values[0]])

def get_markable_previous_words(idx):
    return ' '.join([word_by_idx[x] for x in markables_original_singletons[markables_original_singletons['id'] == idx].previous_words.values[0]])

def get_markable_next_words(idx):
    return ' '.join([word_by_idx[x] for x in markables_original_singletons[markables_original_singletons['id'] == idx].next_words.values[0]])

def get_markable(idx):
    return f'{get_markable_previous_words(idx)} [{get_markable_text(idx).upper()}] {get_markable_next_words(idx)}'.strip()

right_predicted_markables = markables_predicted_singletons[markables_predicted_singletons['is_singleton'].map(lambda x: x[0]) == markables_original_singletons['is_singleton'].map(lambda x: x[0])]
wrong_predicted_markables = markables_predicted_singletons[markables_predicted_singletons['is_singleton'].map(lambda x: x[0]) != markables_original_singletons['is_singleton'].map(lambda x: x[0])]

"""# Analysis of Wrongly Predicted Markables

## Label: singleton, predicted: non-singleton
"""

false_negatives = wrong_predicted_markables[wrong_predicted_markables['is_singleton'].map(lambda x: x[0]) == 1]
false_negative_texts = [get_markable(idx) for idx in false_negatives['id']]

data_to_analyze =  false_negatives

print(f'"nya": {len(list(filter(lambda x: get_markable_text(x) == "nya", data_to_analyze["id"])))}')
print(f'proper name: {len(data_to_analyze[data_to_analyze["is_proper_name"] == 1])}')
print(f'pronoun: {len(data_to_analyze[data_to_analyze["is_pronoun"] == 1])}')   
print(f'pronoun without "nya": {len(data_to_analyze[data_to_analyze["is_pronoun"] == 1]) - len(list(filter(lambda x: get_markable_text(x) == "nya", data_to_analyze["id"])))}')
print(f'first person: {len(data_to_analyze[data_to_analyze["is_first_person"] == 1])}')

data_to_analyze, text_data_to_analyze = false_negatives, false_negative_texts

display(HTML(tabulate([
    [i, idx, escape(text)]
    for i, idx, text
    in zip(range(1, len(data_to_analyze) + 1), data_to_analyze['id'], text_data_to_analyze)
], tablefmt='html')))

"""## Label: non-singleton, predicted: singleton"""

false_positives = wrong_predicted_markables[wrong_predicted_markables['is_singleton'].map(lambda x: x[0]) == 0]
false_positive_texts = [get_markable(idx) for idx in false_positives['id']]

data_to_analyze =  false_positives

print(f'"nya": {len(list(filter(lambda x: get_markable_text(x) == "nya", data_to_analyze["id"])))}')
print(f'proper name: {len(data_to_analyze[data_to_analyze["is_proper_name"] == 1])}')
print(f'pronoun: {len(data_to_analyze[data_to_analyze["is_pronoun"] == 1])}')   
print(f'pronoun without "nya": {len(data_to_analyze[data_to_analyze["is_pronoun"] == 1]) - len(list(filter(lambda x: get_markable_text(x) == "nya", data_to_analyze["id"])))}')
print(f'first person: {len(data_to_analyze[data_to_analyze["is_first_person"] == 1])}')

data_to_analyze, text_data_to_analyze = false_positives, false_positive_texts

display(HTML(tabulate([
    [i, idx, escape(text)]
    for i, idx, text
    in zip(range(1, len(data_to_analyze) + 1), data_to_analyze['id'], text_data_to_analyze)
], tablefmt='html')))

"""# Analysis of Rightly Predicted Markables

## Non-Singletons
"""

true_negatives = right_predicted_markables[right_predicted_markables['is_singleton'].map(lambda x: x[0]) == 1]
true_negative_texts = [get_markable(idx) for idx in true_negatives['id']]

data_to_analyze =  true_negatives

print(f'"nya": {len(list(filter(lambda x: get_markable_text(x) == "nya", data_to_analyze["id"])))}')
print(f'proper name: {len(data_to_analyze[data_to_analyze["is_proper_name"] == 1])}')
print(f'pronoun: {len(data_to_analyze[data_to_analyze["is_pronoun"] == 1])}')   
print(f'pronoun without "nya": {len(data_to_analyze[data_to_analyze["is_pronoun"] == 1]) - len(list(filter(lambda x: get_markable_text(x) == "nya", data_to_analyze["id"])))}')
print(f'first person: {len(data_to_analyze[data_to_analyze["is_first_person"] == 1])}')

data_to_analyze, text_data_to_analyze = true_negatives, true_negative_texts

display(HTML(tabulate([
    [i, idx, escape(text)]
    for i, idx, text
    in zip(range(1, len(data_to_analyze) + 1), data_to_analyze['id'], text_data_to_analyze)
], tablefmt='html')))

"""## Singletons"""

true_positives = right_predicted_markables[right_predicted_markables['is_singleton'].map(lambda x: x[0]) == 0]
true_positive_texts = [get_markable(idx) for idx in true_positives['id']]

data_to_analyze =  true_positives

print(f'"nya": {len(list(filter(lambda x: get_markable_text(x) == "nya", data_to_analyze["id"])))}')
print(f'proper name: {len(data_to_analyze[data_to_analyze["is_proper_name"] == 1])}')
print(f'pronoun: {len(data_to_analyze[data_to_analyze["is_pronoun"] == 1])}')   
print(f'pronoun without "nya": {len(data_to_analyze[data_to_analyze["is_pronoun"] == 1]) - len(list(filter(lambda x: get_markable_text(x) == "nya", data_to_analyze["id"])))}')
print(f'first person: {len(data_to_analyze[data_to_analyze["is_first_person"] == 1])}')

data_to_analyze, text_data_to_analyze = true_positives, true_positive_texts

display(HTML(tabulate([
    [i, idx, escape(text)]
    for i, idx, text
    in zip(range(1, len(data_to_analyze) + 1), data_to_analyze['id'], text_data_to_analyze)
], tablefmt='html')))